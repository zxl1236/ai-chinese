import React, { useState, useEffect, useRef } from 'react';
import './OllamaChatDialog.css';

const OllamaChatDialog = ({ isOpen, onClose }) => {
  const [messages, setMessages] = useState([]);
  const [inputValue, setInputValue] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [selectedModel, setSelectedModel] = useState('deepseek1.8');
  const [connectionStatus, setConnectionStatus] = useState('æ£€æŸ¥ä¸­...');
  const [streamingMessage, setStreamingMessage] = useState('');
  const [useOnlineAPI, setUseOnlineAPI] = useState(false);
  const messagesEndRef = useRef(null);
  const inputRef = useRef(null);

  // å¯ç”¨æœ¬åœ°æ¨¡å‹
  const availableModels = [
    { value: 'deepseek1.8', label: 'DeepSeek 1.8 - æœ¬åœ°æ¨¡å‹' },
  ];

  // åœ¨çº¿APIæ¨¡å‹é€‰é¡¹
  const onlineModels = [
    { value: 'qwen-turbo', label: 'Qwen Turbo - å¿«é€Ÿå“åº”' },
  ];

  const scrollToBottom = () => messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });

  // è¿æ¥æ£€æŸ¥
  const checkOllamaConnection = async () => {
    try {
      const res = await fetch('http://localhost:11434/api/tags');
      if (res.ok) {
        setConnectionStatus('å·²è¿æ¥');
        // åªæœ‰åœ¨å½“å‰é€‰æ‹©çš„æ˜¯æœ¬åœ°æ¨¡å‹æ—¶æ‰è‡ªåŠ¨åˆ‡æ¢åˆ°æœ¬åœ°
        if (!onlineModels.some(m => m.value === selectedModel)) {
          setUseOnlineAPI(false);
        }
        return true;
      } else {
        setConnectionStatus('è¿æ¥é”™è¯¯');
        // åªæœ‰åœ¨å½“å‰é€‰æ‹©çš„æ˜¯æœ¬åœ°æ¨¡å‹æ—¶æ‰è‡ªåŠ¨åˆ‡æ¢
        if (!onlineModels.some(m => m.value === selectedModel)) {
          setUseOnlineAPI(true);
        }
        return false;
      }
    } catch {
      setConnectionStatus('æœªè¿æ¥ - ä½¿ç”¨åœ¨çº¿API');
      // åªæœ‰åœ¨å½“å‰é€‰æ‹©çš„æ˜¯æœ¬åœ°æ¨¡å‹æ—¶æ‰è‡ªåŠ¨åˆ‡æ¢
      if (!onlineModels.some(m => m.value === selectedModel)) {
        setUseOnlineAPI(true);
      }
      return false;
    }
  };

  // å‘é€æ¶ˆæ¯åˆ°åœ¨çº¿API
  const sendMessageToOnlineAPI = async (userMessage) => {
    try {
      const response = await fetch('http://localhost:5000/api/ai/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: userMessage.text,
          model: selectedModel,
          provider: selectedModel.includes('qwen') ? 'qwen' : 'deepseek'
        }),
      });

      if (!response.ok) throw new Error(`HTTP ${response.status}`);

      const result = await response.json();
      
      const aiMsg = {
        id: Date.now() + 1,
        text: result.response || 'æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤ã€‚',
        sender: 'ai',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, aiMsg]);
    } catch (err) {
      const errMsg = {
        id: Date.now() + 1,
        text: `åœ¨çº¿APIè°ƒç”¨å¤±è´¥ï¼š${err.message}ã€‚è¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦å¯åŠ¨ã€‚`,
        sender: 'ai',
        isError: true,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errMsg]);
    }
  };

  // å‘é€æ¶ˆæ¯åˆ°æœ¬åœ°Ollama
  const sendMessageToOllama = async (userMessage) => {
    try {
      const response = await fetch('http://localhost:11434/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: selectedModel,
          messages: [
            ...messages.map(m => ({ role: m.sender === 'user' ? 'user' : 'assistant', content: m.text })),
            { role: 'user', content: userMessage.text },
          ],
          stream: true,
          options: { temperature: 0.7, top_p: 0.9, num_predict: 2048 },
        }),
      });

      if (!response.ok) throw new Error(`HTTP ${response.status}`);

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let full = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        const chunk = decoder.decode(value);
        for (const line of chunk.split('\n')) {
          if (!line.trim()) continue;
          try {
            const data = JSON.parse(line);
            if (data.message?.content) {
              full += data.message.content;
              setStreamingMessage(full);
            }
          } catch {
            // å¿½ç•¥åŠåŒ…
          }
        }
      }

      const aiMsg = {
        id: Date.now() + 1,
        text: full || 'æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤ã€‚',
        sender: 'ai',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, aiMsg]);
      setStreamingMessage('');
    } catch (err) {
      const errMsg = {
        id: Date.now() + 1,
        text: `æœ¬åœ°Ollamaè¿æ¥å¤±è´¥ï¼š${err.message}ã€‚æ­£åœ¨åˆ‡æ¢åˆ°åœ¨çº¿API...`,
        sender: 'ai',
        isError: true,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errMsg]);
      
      // è‡ªåŠ¨åˆ‡æ¢åˆ°åœ¨çº¿API
      setUseOnlineAPI(true);
      setConnectionStatus('è‡ªåŠ¨åˆ‡æ¢åˆ°åœ¨çº¿API');
      
      // é‡è¯•å‘é€æ¶ˆæ¯
      await sendMessageToOnlineAPI(userMessage);
    }
  };

  // å‘é€æ¶ˆæ¯
  const sendMessage = async () => {
    if (!inputValue.trim() || isLoading) return;

    const userMessage = {
      id: Date.now(),
      text: inputValue.trim(),
      sender: 'user',
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInputValue('');
    setIsLoading(true);
    setStreamingMessage('');

    try {
      // æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç±»å‹å†³å®šä½¿ç”¨å“ªä¸ªAPI
      const isOnlineModel = onlineModels.some(m => m.value === selectedModel);
      if (isOnlineModel || useOnlineAPI) {
        await sendMessageToOnlineAPI(userMessage);
      } else {
        await sendMessageToOllama(userMessage);
      }
    } finally {
      setIsLoading(false);
    }
  };

  const clearMessages = () => { setMessages([]); setStreamingMessage(''); };

  const handleKeyDown = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const autoGrow = () => {
    if (!inputRef.current) return;
    inputRef.current.style.height = 'auto';
    inputRef.current.style.height = Math.min(inputRef.current.scrollHeight, 200) + 'px';
  };

  useEffect(() => {
    if (isOpen) {
      checkOllamaConnection();
      const it = setInterval(checkOllamaConnection, 30000);
      return () => clearInterval(it);
    }
  }, [isOpen]);

  useEffect(scrollToBottom, [messages, streamingMessage]);
  useEffect(() => { if (isOpen) setTimeout(() => inputRef.current?.focus(), 100); }, [isOpen]);
  useEffect(autoGrow, [inputValue]);

  if (!isOpen) return null;

  const hasMessages = messages.length > 0;

  return (
    <div className="cgpt-overlay">
      <div className="cgpt-shell">
        {/* é¡¶æ  */}
        <header className="cgpt-topbar">
          <div className="cgpt-topbar-inner">
            <div className="cgpt-brand">AI åŠ©æ‰‹</div>
            <div className="cgpt-tools">
              <select
                className="cgpt-model"
                value={selectedModel}
                onChange={(e) => {
                  const newModel = e.target.value;
                  setSelectedModel(newModel);
                  // æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç±»å‹è‡ªåŠ¨è®¾ç½®APIæ¨¡å¼
                  const isOnlineModel = onlineModels.some(m => m.value === newModel);
                  setUseOnlineAPI(isOnlineModel);
                }}
              >
                <optgroup label="æœ¬åœ°æ¨¡å‹ (Ollama)">
                  {availableModels.map(m => <option key={m.value} value={m.value}>{m.label}</option>)}
                </optgroup>
                <optgroup label="åœ¨çº¿API">
                  {onlineModels.map(m => <option key={m.value} value={m.value}>{m.label}</option>)}
                </optgroup>
              </select>
              <button 
                className={`cgpt-toggle-api ${useOnlineAPI ? 'online' : 'local'}`}
                onClick={() => {
                  const newMode = !useOnlineAPI;
                  setUseOnlineAPI(newMode);
                  // å¦‚æœåˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å¼ï¼Œè‡ªåŠ¨é€‰æ‹©æœ¬åœ°æ¨¡å‹
                  if (!newMode) {
                    setSelectedModel(availableModels[0].value);
                  }
                  // å¦‚æœåˆ‡æ¢åˆ°åœ¨çº¿æ¨¡å¼ï¼Œè‡ªåŠ¨é€‰æ‹©åœ¨çº¿æ¨¡å‹
                  else {
                    setSelectedModel(onlineModels[0].value);
                  }
                }}
                title={useOnlineAPI ? 'åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹' : 'åˆ‡æ¢åˆ°åœ¨çº¿API'}
              >
                {useOnlineAPI ? 'ğŸŒ åœ¨çº¿' : 'ğŸ’» æœ¬åœ°'}
              </button>
              <div className={`cgpt-conn ${connectionStatus === 'å·²è¿æ¥' ? 'ok' : connectionStatus === 'è¿æ¥é”™è¯¯' ? 'warn' : 'off'}`}>
                <span className="dot" />
                {connectionStatus}
              </div>
              <button className="cgpt-close" onClick={onClose} aria-label="å…³é—­">âœ•</button>
            </div>
          </div>
        </header>

        {/* æ¶ˆæ¯æµ */}
        <main className={`cgpt-main ${hasMessages ? 'with' : 'empty'}`}>
          {!hasMessages && (
            <div className="cgpt-empty">
              <div className="emoji">ğŸ’¬</div>
              <h3>æœ‰ä»€ä¹ˆå¯ä»¥å¸®å¿™çš„ï¼Ÿ</h3>
              <p>æå‡ºé—®é¢˜æˆ–ç²˜è´´æ–‡æœ¬ï¼Œæˆ‘ä¼šåƒ ChatGPT ä¸€æ ·å›ç­”ã€‚</p>
            </div>
          )}

          {hasMessages && (
            <div className="cgpt-thread">
              {messages.map(msg => (
                <section
                  key={msg.id}
                  className={`cgpt-msg ${msg.sender === 'user' ? 'user' : 'ai'} ${msg.isError ? 'error' : ''}`}
                >
                  <div className="avatar">{msg.sender === 'user' ? 'ğŸ‘¤' : (msg.isError ? 'âš ï¸' : 'ğŸ¤–')}</div>
                  <div className="content">
                    {msg.text}
                  </div>
                </section>
              ))}

              {/* æµå¼æ˜¾ç¤º */}
              {isLoading && streamingMessage && (
                <section className="cgpt-msg ai">
                  <div className="avatar">ğŸ¤–</div>
                  <div className="content streaming">
                    {streamingMessage}<span className="caret">|</span>
                  </div>
                </section>
              )}

              {/* "AI æ­£åœ¨æ€è€ƒâ€¦" å ä½ï¼ˆæ— æµç‰‡æ®µæ—¶ï¼‰ */}
              {isLoading && !streamingMessage && (
                <div className="cgpt-thinking">
                  <div className="dots"><i/><i/><i/></div>
                  <span>AI æ­£åœ¨æ€è€ƒâ€¦</span>
                </div>
              )}
              <div ref={messagesEndRef} />
            </div>
          )}
        </main>

        {/* è¾“å…¥åŒºï¼ˆå¸åº•ï¼‰ */}
        <footer className="cgpt-composer">
          <div className="cgpt-composer-inner">
            <div className="input-wrap">
              <textarea
                ref={inputRef}
                className="input"
                value={inputValue}
                placeholder="è¯¢é—®ä»»ä½•é—®é¢˜"
                onChange={(e) => setInputValue(e.target.value)}
                onKeyDown={handleKeyDown}
                rows={1}
                disabled={isLoading}
              />
              <button
                className="send"
                onClick={sendMessage}
                disabled={!inputValue.trim() || isLoading}
                title="å‘é€"
              >
                â¤
              </button>
            </div>

            {messages.length > 0 && (
              <div className="composer-actions">
                <button className="clear" onClick={clearMessages} disabled={isLoading}>æ¸…ç©ºå¯¹è¯</button>
              </div>
            )}

            <div className="hint">ChatGPT ä¹Ÿå¯èƒ½ä¼šçŠ¯é”™ï¼Œè¯·æ ¸å¯¹é‡è¦ä¿¡æ¯ã€‚</div>
          </div>
        </footer>
      </div>
    </div>
  );
};

export default OllamaChatDialog;